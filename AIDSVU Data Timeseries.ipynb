{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import us\n",
    "import matplotlib # for testing\n",
    "%matplotlib inline\n",
    "\n",
    "# A list of all the URLs to state and county newdx data sets\n",
    "raw_newdx_urls = {\n",
    "    2015: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_NewDX_2015.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_NewDX_2015.xlsx\"},\n",
    "    2014: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_NewDX_2014.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_NewDX_2014.xlsx\"},\n",
    "    2013: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_NewDX_2013.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_NewDX_2013.xlsx\"},\n",
    "    2012: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_NewDX_2012.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_NewDX_2012.xlsx\"},\n",
    "    2011: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_NewDX_2011.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_NewDX_2011.xlsx\"},\n",
    "    2010: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_NewDX_2010.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_NewDX_2010.xlsx\"},\n",
    "    2009: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_NewDX_2009.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_NewDX_2009.xlsx\"},\n",
    "    2008: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_NewDX_2008.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_NewDX_2008.xlsx\"}\n",
    "}\n",
    "\n",
    "# A list of all the URLs to state and county prev data sets.\n",
    "# Note that there is no prevalence data for 2008, 2009, or 2015.\n",
    "raw_prev_urls = {\n",
    "    2014: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_Prev_2014.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_Prev_2014.xlsx\"},\n",
    "    2013: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_Prev_2013.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_Prev_2013v2.xlsx\"},\n",
    "    2012: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_2012-2-1.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_2012-1.xls\"},\n",
    "    2011: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_20111.xlsx\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_2011-1-1.xlsx\"},\n",
    "    2010: {\"state\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_State_2010-1.xls\",\n",
    "        \"county\":\"https://github.com/jamiekasulis/aidsvu_data_grab/raw/master/AIDSVu_County_20101.xls\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_df(year, sc, dataset):\n",
    "    \"\"\"\n",
    "    Returns a raw, uncleaned dataframe corresponding to year and state or county in either raw_newdx_urls or raw_prev_urls.\n",
    "    year is a full four-digit year int, sc is the string \"state\" or \"county\", and dataset is the string \"prev\" or \"newdx\".\n",
    "    \"\"\"\n",
    "    if dataset == \"newdx\":\n",
    "        return pd.read_excel(raw_newdx_urls.get(year).get(sc), skiprows=2)\n",
    "    elif dataset == \"prev\":\n",
    "        if year == 2012:\n",
    "            # 2012 is a special case where you should not skip any rows.\n",
    "            return pd.read_excel(raw_prev_urls.get(year).get(sc), skiprows=0)\n",
    "        elif year == 2011:\n",
    "            return pd.read_excel(raw_prev_urls.get(year).get(sc), skiprows=0)\n",
    "        elif year == 2010:\n",
    "            return pd.read_excel(raw_prev_urls.get(year).get(sc), skiprows=0)\n",
    "        else:\n",
    "            return pd.read_excel(raw_prev_urls.get(year).get(sc), skiprows=2)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omit_us_territories(countydf):\n",
    "    \"\"\"\n",
    "    Takes a county data frame and returns a version of it that only includes the 50 U.S. states.\n",
    "    This is a helper function for clean_newdx_dfs()\n",
    "    \"\"\"\n",
    "    # newdx uses GEO ID\n",
    "    if 'GEO ID' in countydf.columns:\n",
    "        countydf = countydf[countydf['GEO ID'].astype('int64') < 60000]\n",
    "    # prev uses County FIPS Code\n",
    "    elif 'County FIPS Code' in countydf.columns:\n",
    "        countydf = countydf[countydf['County FIPS Code'].astype('int64') < 60000]\n",
    "    \n",
    "    if 'State' in countydf.columns:\n",
    "        countydf = countydf[countydf['State'] != 'NaN']\n",
    "\n",
    "    return countydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_abbreviations(df):\n",
    "    \"\"\"\n",
    "    Checks to see if the values in the 'state' column are not full state names, but abbreviations.\n",
    "    If that it is the case, it will convert each abbreviation to the full state name.\n",
    "    \"\"\"\n",
    "    us_state_abbrev = {\n",
    "        'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO',\n",
    "        'Connecticut': 'CT','Delaware': 'DE','Florida': 'FL','Georgia': 'GA','Hawaii': 'HI','Idaho': 'ID','Illinois': 'IL',\n",
    "        'Indiana': 'IN','Iowa': 'IA','Kansas': 'KS','Kentucky': 'KY','Louisiana': 'LA','Maine': 'ME','Maryland': 'MD',\n",
    "        'Massachusetts': 'MA','Michigan': 'MI','Minnesota': 'MN','Mississippi': 'MS','Missouri': 'MO','Montana': 'MT',\n",
    "        'Nebraska': 'NE','Nevada': 'NV','New Hampshire': 'NH','New Jersey': 'NJ','New Mexico': 'NM','New York': 'NY',\n",
    "        'North Carolina': 'NC','North Dakota': 'ND','Ohio': 'OH','Oklahoma': 'OK','Oregon': 'OR','Pennsylvania': 'PA',\n",
    "        'Rhode Island': 'RI','South Carolina': 'SC','South Dakota': 'SD','Tennessee': 'TN','Texas': 'TX',\n",
    "        'Utah': 'UT','Vermont': 'VT','Virginia': 'VA','Washington': 'WA','West Virginia': 'WV','Wisconsin': 'WI',\n",
    "        'Wyoming': 'WY', 'Washington, DC' : 'DC', 'Puerto Rico' : 'PR'\n",
    "    }\n",
    "    # Make the keys the values, and vice versa.\n",
    "    us_state_abbrev = { val:key for (key, val) in us_state_abbrev.items() }\n",
    "    # Convert every state in the column\n",
    "    for s in range(len(df['State'])):\n",
    "        abbr = df['State'].iloc[s]\n",
    "        if type(abbr) == str:\n",
    "            if len(abbr) > 2:\n",
    "                break\n",
    "            else:\n",
    "                 df['State'].replace([abbr], us_state_abbrev[abbr], inplace=True)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_raw_df for all newdx data and store in newdx_dfs\n",
    "def make_clean_newdx_dfs():\n",
    "    \"\"\"\n",
    "    Makes and returns a dictionary of newdx data indexed by year and state/county.\n",
    "    County data will have their U.S. territories removed.\n",
    "    \"\"\"\n",
    "    newdx_dfs = {}\n",
    "    for year in raw_newdx_urls.keys():\n",
    "        # make the data frames\n",
    "        # strip columns and set them to lower case\n",
    "        newdx_dfs[year] = {\"state\": convert_abbreviations(omit_us_territories(make_raw_df(year, 'state', 'newdx'))).rename(columns=lambda x: x.strip().lower()),\n",
    "                       \"county\": convert_abbreviations(omit_us_territories(make_raw_df(year, 'county', 'newdx'))).rename(columns=lambda x: x.strip().lower())}\n",
    "        \n",
    "    return newdx_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_raw_df for all prev data and store in prev_dfs\n",
    "def make_clean_prev_dfs():\n",
    "    \"\"\"\n",
    "    Makes and returns a dictionary of prevalence data indexed by year and state/county.\n",
    "    County data will have their U.S. territories removed.\n",
    "    \"\"\"\n",
    "    prev_dfs = {}\n",
    "    for year in raw_prev_urls.keys():\n",
    "        prev_dfs[year] = {\"state\": convert_abbreviations(omit_us_territories(make_raw_df(year, 'state', 'prev'))).rename(columns=lambda x: x.strip().lower()),\n",
    "                       \"county\": convert_abbreviations(omit_us_territories(make_raw_df(year, 'county', 'prev'))).rename(columns=lambda x: x.strip().lower())}\n",
    "\n",
    "    return prev_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_dfs = make_clean_prev_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdx_dfs = make_clean_newdx_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_or_county(loc_name):\n",
    "    \"\"\"\n",
    "    A helper function for to_timeseries. Returns 'state' if loc_name is a state and 'county' otherwise.\n",
    "    \"\"\"\n",
    "    if loc_name in us.STATES:\n",
    "        return 'state'\n",
    "    else:\n",
    "        return 'county'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_proper_dataset(column_name, loc_type):\n",
    "    \"\"\"\n",
    "    A helper function for determine_proper_years() and to_timeseries().\n",
    "    Returns either newdx_dfs or prev_dfs, whichever one has a column called column_name.\n",
    "    loc_type should be either 'city' or 'county'\n",
    "    \"\"\"\n",
    "    # Check newdx_dfs first.\n",
    "    for year in newdx_dfs.keys():\n",
    "        df = newdx_dfs[year][loc_type]\n",
    "        df_cols = df.columns.tolist()\n",
    "        if column_name in df_cols:\n",
    "            return newdx_dfs\n",
    "    \n",
    "    # Check prev_dfs\n",
    "    for year in prev_dfs.keys():\n",
    "        df = prev_dfs[year][loc_type]\n",
    "        df_cols = df.columns.tolist()\n",
    "        if column_name in df_cols:\n",
    "            return prev_dfs\n",
    "        \n",
    "\n",
    "    print(\"ERROR: column_name does not exist in newdx_dfs or prev_dfs based on argument loc_type (county or city).\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the proper start and end years to build the time series on.\n",
    "# If start_year is not a key in the dictionary of data frames, do the closest year working DOWN\n",
    "# For end_year, do the closest year working UP.\n",
    "def determine_proper_years(start_year, end_year, data_dict):\n",
    "    \"\"\"\n",
    "    A helper function for to_timeseries. It verifies that data_dict has data for start_year and end_year.\n",
    "    If not, it will return the minimum start_year and maximum end_year to make a time series as wide as possible.\n",
    "    Returns a list [start, end]\n",
    "    data_dict should be prev_dfs or newdx_dfs.\n",
    "    \"\"\"\n",
    "    start = None\n",
    "    end = None\n",
    "    \n",
    "    if start_year in data_dict.keys():\n",
    "        start = start_year\n",
    "    else:\n",
    "        start = min(list(data_dict.keys()))\n",
    "    if end_year in data_dict.keys():\n",
    "        end = end_year\n",
    "    else:\n",
    "        end = max(list(data_dict.keys()))\n",
    "\n",
    "    return [start, end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_years(year_range, data_dict):\n",
    "    \"\"\"\n",
    "    A helper function for get_timeseries.\n",
    "    Given a 2-element list [start_year, end_year] and a data_dict that is either newdx_dfs or prev_dfs,\n",
    "    return an ordered list (ascending) of years that are actually in data_dict.\n",
    "    This function is meant to account for the fact that there may be missing years of data.\n",
    "    \"\"\"\n",
    "    start = year_range[0]\n",
    "    end = year_range[1]\n",
    "    \n",
    "    years = list(range(start, end+1)) # all the years in year_range\n",
    "    proper_years = [] # ordered list of the years in year_range that we have data for\n",
    "    \n",
    "    # add the years that we have data for to proper_years\n",
    "    keys = data_dict.keys()\n",
    "    for year in years:\n",
    "        if year in keys:\n",
    "            proper_years.append(year)\n",
    "    \n",
    "    # impose ascending order on proper_years\n",
    "    proper_years.sort()\n",
    "    return proper_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_timeseries(column_name, start_year, end_year, location, state = \"n/a\", data_dict = \"n/a\"):\n",
    "    \"\"\"\n",
    "    Returns a 2D table (year x value) going from start_year to end_year, where the values are from whichever column in\n",
    "    either newdx or prev data that matches the column_name argument.\n",
    "    The argument data_set should be either \"prev\" or \"newdx\". Defaults to newdx if no value is passed.\n",
    "    Defaults to 2008 and 2014 for start and end years.\n",
    "    data_dict may be either newdx_dfs or prev_dfs. This is an optional argument passed by create_timeseries_dataframe()\n",
    "    to save some work.\n",
    "    \"\"\"\n",
    "    # set loc_header\n",
    "    sc = state_or_county(location)\n",
    "    if sc == 'county' and state == 'n/a':\n",
    "        print(\"You must include the name of the state with the county!\")\n",
    "        return\n",
    "    \n",
    "    if sc == 'state':\n",
    "        loc_header = 'state'\n",
    "        loc_type = 'state'\n",
    "    else:\n",
    "        loc_header = 'county name'\n",
    "        loc_type = 'county'\n",
    "    \n",
    "    # Grab the dictionary of data frames that we should be looking for column_name in\n",
    "    if data_dict == 'n/a':\n",
    "        data_dict = determine_proper_dataset(column_name, loc_type)\n",
    "    elif data_dict == 'prev':\n",
    "        data_dict = prev_dfs\n",
    "    elif data_dict == 'newdx':\n",
    "        data_dict = newdx_dfs\n",
    "    else:\n",
    "        print(\"Invalid data_dict passed!\")\n",
    "        return\n",
    "    \n",
    "    # Verify that the time range is valid\n",
    "    time_range = determine_proper_years(start_year, end_year, data_dict)\n",
    "    \n",
    "    # Make an ordered list of the valid years in the time range (there may be holes), which we will iterate through later\n",
    "    data_years = get_valid_years(time_range, data_dict)\n",
    "    \n",
    "    # Create the time series.\n",
    "    time_series = pd.DataFrame(columns = ['year', column_name])\n",
    "    \n",
    "    # Iterate through every year in data_years, grabbing the value for column_name and storing it to the dataframe\n",
    "    # called time_series.\n",
    "    for dy in data_years:\n",
    "        # If we are looking at counties, we need to match both county name and state\n",
    "        if sc == 'county':\n",
    "            current_df = data_dict[dy][loc_type][data_dict[dy][loc_type]['state'] == state]\n",
    "        \n",
    "        # Otherwise, we are guaranteed no duplicate states\n",
    "        else:\n",
    "            current_df = data_dict[dy][loc_type]\n",
    "        \n",
    "        # Append the new value to the dataframe\n",
    "        #print(\"dy=\" + str(dy) + \" of \" + location)\n",
    "        value = current_df[current_df[loc_header] == location][column_name].iloc[0]\n",
    "        time_series = time_series.append({'year': dy, column_name: value}, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    return time_series[['year', column_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>new diagnoses rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year new diagnoses rate\n",
       "0  2010                 14\n",
       "1  2011                 13\n",
       "2  2012                 10\n",
       "3  2013                 12\n",
       "4  2014                 13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_timeseries('new diagnoses rate', 2010, 2014, 'Fairfield County', 'Connecticut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy=2010 of Connecticut\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2d2ce8f7aa6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test: state prev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mto_timeseries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'black rate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2010\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2014\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Connecticut'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'state'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-a5f862c8b0ca>\u001b[0m in \u001b[0;36mto_timeseries\u001b[1;34m(column_name, start_year, end_year, location, state, data_dict)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m# Append the new value to the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dy=\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc_header\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mtime_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_series\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1478\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1480\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2101\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2102\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2007\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2009\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2011\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Test: state prev\n",
    "to_timeseries('black rate', 2010, 2014, 'Connecticut', 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: column_name does not exist in newdx_dfs or prev_dfs based on argument loc_type (county or city).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-161ab7f96a24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mto_timeseries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new diagnoses state rate'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m2008\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2014\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Connecticut'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'state'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-a5f862c8b0ca>\u001b[0m in \u001b[0;36mto_timeseries\u001b[1;34m(column_name, start_year, end_year, location, state, data_dict)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Verify that the time range is valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mtime_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetermine_proper_years\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Make an ordered list of the valid years in the time range (there may be holes), which we will iterate through later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-354c6fb108f3>\u001b[0m in \u001b[0;36mdetermine_proper_years\u001b[1;34m(start_year, end_year, data_dict)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mstart_year\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_year\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "to_timeseries('new diagnoses state rate',  2008, 2014, 'Connecticut', 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: column_name does not exist in newdx_dfs or prev_dfs based on argument loc_type (county or city).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-042a0d485242>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test: state newdx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mto_timeseries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new diagnoses black rate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2008\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2018\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Connecticut'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'state'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-a5f862c8b0ca>\u001b[0m in \u001b[0;36mto_timeseries\u001b[1;34m(column_name, start_year, end_year, location, state, data_dict)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Verify that the time range is valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mtime_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetermine_proper_years\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Make an ordered list of the valid years in the time range (there may be holes), which we will iterate through later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-354c6fb108f3>\u001b[0m in \u001b[0;36mdetermine_proper_years\u001b[1;34m(start_year, end_year, data_dict)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mstart_year\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_year\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# Test: state newdx\n",
    "to_timeseries('new diagnoses black rate', 2008, 2018, 'Connecticut', 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy=2008 of Fairfield County\n",
      "dy=2009 of Fairfield County\n",
      "dy=2010 of Fairfield County\n",
      "dy=2011 of Fairfield County\n",
      "dy=2012 of Fairfield County\n",
      "dy=2013 of Fairfield County\n",
      "dy=2014 of Fairfield County\n",
      "dy=2015 of Fairfield County\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>new diagnoses rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year new diagnoses rate\n",
       "0  2008                 15\n",
       "1  2009                 14\n",
       "2  2010                 14\n",
       "3  2011                 13\n",
       "4  2012                 10\n",
       "5  2013                 12\n",
       "6  2014                 13\n",
       "7  2015                  8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test: county newdx\n",
    "to_timeseries('new diagnoses rate', 2008, 2018, 'Fairfield County', 'Connecticut')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build timeseries CSVs\n",
    "Every county is a row, and each column is a year.\n",
    "* total rate x (prev and new dx) = 2 dfs\n",
    "* black, white, hispanic rates x (prev and new dx) = 6 sheets\n",
    "* men black, white, hispanic rates x (prev and new dx) = 6 sheets\n",
    "* women black, white, hispanic rates x (prev and new dx) = 6 sheets\n",
    "\n",
    "Naming convention:\n",
    "* ts_men_black_prev_rate.csv\n",
    "* ts_black_newdx_rate.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timeseries_dataframe(column_name, data_set, startyear=2008, endyear=2020):\n",
    "    \"\"\"\n",
    "    Grabs column_name for each county in data_set dataframes, where data_set is either 'newdx' for newdx_dfs\n",
    "    or 'prev' for prev_dfs,\n",
    "    from startyear to endyear. (Will default to the full range of data available).\n",
    "    \n",
    "    Dataframe will have the following format:\n",
    "                     geo_id  2008   2009   ...\n",
    "    county, state   |###    |###  | ###  | ...\n",
    "\n",
    "    This is a helper function for create_csv().\n",
    "    \"\"\"\n",
    "    # Get proper dictionary, either newdx_dfs or prev_dfs\n",
    "    if data_set == 'newdx':\n",
    "        data_dict = newdx_dfs\n",
    "    elif data_set == 'prev':\n",
    "        data_dict = prev_dfs\n",
    "    else:\n",
    "        print(\"Invalid data_set passed to create_timeseries_dataframe!\")\n",
    "        return\n",
    "    \n",
    "    all_timeseries = pd.DataFrame()\n",
    "    row_indices = [] # a list of all the county names, in the order that they are added. We will make this our df index.\n",
    "    column_headers = None\n",
    "    \n",
    "    # Iterate through every row (county). Create a time series for each one, appending to the one before it.\n",
    "    for index, row in data_dict[startyear]['county'].iterrows():\n",
    "        county = row['county name']\n",
    "        state = row['state']\n",
    "        \n",
    "        # create time series df for current county\n",
    "        ts = to_timeseries(column_name, startyear, endyear, county, state, data_set)\n",
    "        \n",
    "        # add county, state to row_indices so we can index with this later\n",
    "        row_indices.append(county + \", \" + state)\n",
    "        #transpose to have years as headers\n",
    "        ts = ts.transpose()\n",
    "        \n",
    "        # save the years for columns. Can rewrite this code so we only have to do this once, but later...\n",
    "        column_headers = ts.iloc[0]\n",
    "        \n",
    "        # now append this to all_timeseries\n",
    "        all_timeseries = all_timeseries.append(ts.iloc[1]) # iloc[1] because iloc[0] is a row of false headers now\n",
    "    \n",
    "    # Change the columns and index of all_timeseries\n",
    "    all_timeseries.columns = column_headers\n",
    "    all_timeseries.index = row_indices\n",
    "    \n",
    "    return all_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = create_timeseries_dataframe('new diagnoses rate', 'newdx', 2008, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autauga County, Alabama</th>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baldwin County, Alabama</th>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbour County, Alabama</th>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bibb County, Alabama</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blount County, Alabama</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year                     2008  2009  2010  2011  2012  2013  2014  2015\n",
       "Autauga County, Alabama  20.0  17.0  -1.0  16.0  16.0  -1.0  13.0  11.0\n",
       "Baldwin County, Alabama  12.0   9.0   7.0  13.0   8.0   6.0  10.0   9.0\n",
       "Barbour County, Alabama  24.0  20.0  -1.0  22.0  -1.0  -1.0  -1.0  -1.0\n",
       "Bibb County, Alabama     -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0\n",
       "Blount County, Alabama   -1.0  15.0  -1.0  -1.0  -1.0  -1.0  10.0  -1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>new diagnoses rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year new diagnoses rate\n",
       "0  2008                 20\n",
       "1  2009                 17\n",
       "2  2010                 -1\n",
       "3  2011                 16\n",
       "4  2012                 16\n",
       "5  2013                 -1\n",
       "6  2014                 13\n",
       "7  2015                 11"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_timeseries('new diagnoses rate', 2008, 2018, 'Autauga County', 'Alabama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
